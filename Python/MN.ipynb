{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca93539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2021.09.4 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import wget\n",
    "import urllib.parse\n",
    "import argparse\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pubchempy as pcp\n",
    "\n",
    "\n",
    "from pybatchclassyfire import *\n",
    "from pandas import json_normalize\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdFMCS\n",
    "from rdkit.Chem import PandasTools\n",
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2e59881",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_postproc(entry = \"/Users/mahnoorzulfiqar/Downloads/New_ms2_spectra_endo_pos\", Source=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad26be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_postproc(entry, Source=\"all\"):\n",
    "    # currently only these subsets are removed from the names from GNPS\n",
    "    matches = [\n",
    "        \"M+\",\n",
    "        \"[M\",\n",
    "        \"M-\",\n",
    "        \"2M\",\n",
    "        \"M*\", \n",
    "        \"20.0\",\n",
    "        \"50.0\",\n",
    "        \"30.0\",\n",
    "        \"40.0\",\n",
    "        \"60.0\",\n",
    "        \"70.0\",\n",
    "        \"eV\",\n",
    "        \"Massbank\",\n",
    "        \"Spectral\",\n",
    "        \"Match\",\n",
    "        \"to\",\n",
    "        \"from\",\n",
    "        \"NIST14\",\n",
    "        \"MoNA\",\n",
    "        \"[IIN-based:\",\n",
    "        \"[IIN-based\",\n",
    "        \"on:\",\n",
    "        \"CCMSLIB00003136269]\",\n",
    "        \"CollisionEnergy:\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Define scoring for all DBs\n",
    "    def HMDB_Scoring(db, i):\n",
    "        if (\n",
    "            db[\"HMDBintScore\"][i] >= 0.50\n",
    "            and db[\"HMDBmzScore\"][i] >= 0.50\n",
    "            and db[\"HQMatchingPeaks\"][i] / db[\"hQueryTotalPeaks\"][i] >= 0.50\n",
    "        ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def GNPS_Scoring(db, i):\n",
    "        if (\n",
    "            db[\"GNPSintScore\"][i] >= 0.50\n",
    "            and db[\"GNPSmzScore\"][i] >= 0.50\n",
    "            and db[\"GQMatchingPeaks\"][i] / db[\"gQueryTotalPeaks\"][i] >= 0.50\n",
    "        ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def MB_Scoring(db, i):\n",
    "        if (\n",
    "            db[\"MBintScore\"][i] >= 0.50\n",
    "            and db[\"MBmzScore\"][i] >= 0.50\n",
    "            and db[\"MQMatchingPeaks\"][i] / db[\"mQueryTotalPeaks\"][i] >= 0.50\n",
    "        ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    # in case if we need HMDB later\n",
    "    if os.path.exists(entry.split(\"/DS\")[0] + \"/hmdb_dframe_str.csv\"):\n",
    "        extract_smiles = pd.read_csv(entry.split(\"/DS\")[0] + \"/hmdb_dframe_str.csv\", low_memory=False)\n",
    "   \n",
    "\n",
    "    msp_file = glob.glob(\n",
    "        entry + \"/spectral_dereplication\" + \"/*.csv\"\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    if len(msp_file) > 0:\n",
    "\n",
    "        if os.path.exists(msp_file[0]):\n",
    "\n",
    "            msp = pd.read_csv(msp_file[0])\n",
    "            msp[\"mbank_results_csv\"] = np.nan\n",
    "            msp[\"gnps_results_csv\"] = np.nan\n",
    "            msp[\"hmdb_results_csv\"] = np.nan\n",
    "            # enter the directory with /spectral_dereplication/ results\n",
    "\n",
    "            # enter the directory with /spectral_dereplication/ results\n",
    "            # GNPS Results\n",
    "            if Source == \"gnps\" or Source == \"all\":\n",
    "\n",
    "                # print(entry)\n",
    "                # enter the directory with /spectral_dereplication/ results\n",
    "                sub_dir = (\n",
    "                    entry + \"/spectral_dereplication/GNPS/\"\n",
    "                )\n",
    "\n",
    "                if os.path.exists(sub_dir):\n",
    "                    files = glob.glob(sub_dir + \"/*.csv\")\n",
    "                    # print(files)\n",
    "                    files = [item for item in files if 'proc' not in item]\n",
    "\n",
    "                    for mz, row in msp.iterrows():\n",
    "                        for fls_g in files:\n",
    "\n",
    "                            if msp[\"id_X\"][mz] in fls_g:\n",
    "                                \n",
    "                                gnps_df = pd.read_csv(fls_g)\n",
    "                                if len(gnps_df) > 0:\n",
    "\n",
    "                                    for i, row in gnps_df.iterrows():\n",
    "                                        # if compound name is present\n",
    "\n",
    "                                        if GNPS_Scoring(gnps_df, i):\n",
    "                                            \n",
    "                                            if not isNaN(\n",
    "                                                gnps_df[\"GNPScompound_name\"][i]\n",
    "                                            ):\n",
    "                                                # split if there is a gap in the names\n",
    "\n",
    "                                                string_chng = gnps_df[\n",
    "                                                    \"GNPScompound_name\"\n",
    "                                                ][i].split(\" \")\n",
    "\n",
    "                                                # create an empty list\n",
    "                                                newstr = []\n",
    "\n",
    "                                                # for each part of the string in the names\n",
    "                                                chng = []\n",
    "\n",
    "                                                for j in range(\n",
    "                                                    len(string_chng)\n",
    "                                                ):\n",
    "                                                    # check if the substrings are present in the matches and no - is present\n",
    "\n",
    "                                                    if not any(\n",
    "                                                        x in string_chng[j]\n",
    "                                                        for x in matches\n",
    "                                                    ):  # and not '-' == string_chng[j]:\n",
    "\n",
    "                                                        # IF | and ! not in the substring\n",
    "                                                        if (\n",
    "                                                            \"|\"\n",
    "                                                            not in string_chng[\n",
    "                                                                j\n",
    "                                                            ]\n",
    "                                                            or \"!\"\n",
    "                                                            not in string_chng[\n",
    "                                                                j\n",
    "                                                            ]\n",
    "                                                        ):\n",
    "\n",
    "                                                            newstr.append(\n",
    "                                                                string_chng[j]\n",
    "                                                            )\n",
    "                                                        # if | present in the substring\n",
    "                                                        elif (\n",
    "                                                            \"|\"\n",
    "                                                            in string_chng[j]\n",
    "                                                        ):\n",
    "\n",
    "                                                            # split the string\n",
    "                                                            jlen = string_chng[\n",
    "                                                                j\n",
    "                                                            ].split(\"|\")\n",
    "                                                            # how many substrings are left now\n",
    "                                                            lst = len(jlen) - 1\n",
    "                                                            # append this to chng\n",
    "                                                            chng.append(\n",
    "                                                                jlen[lst]\n",
    "                                                            )\n",
    "                                                            break\n",
    "\n",
    "                                                            # now append chng to newstr\n",
    "                                                chng.append(\" \".join(newstr))\n",
    "\n",
    "                                                # save this as the correct name\n",
    "                                                gnps_df.loc[\n",
    "                                                    i, \"corr_names\"\n",
    "                                                ] = chng[0]\n",
    "\n",
    "                                                if not isNaN(\n",
    "                                                    gnps_df[\"GNPSSMILES\"][i]\n",
    "                                                ):\n",
    "                                                    if chng == \"\":\n",
    "                                                        break\n",
    "                                                    elif gnps_df[\"GNPSSMILES\"][\n",
    "                                                        i\n",
    "                                                    ].isalpha():\n",
    "                                                        s = pcp.get_compounds(\n",
    "                                                            chng[0], \"name\"\n",
    "                                                        )\n",
    "                                                        if s:\n",
    "                                                            for comp in s:\n",
    "                                                                gnps_df[\n",
    "                                                                    \"GNPSSMILES\"\n",
    "                                                                ][\n",
    "                                                                    i\n",
    "                                                                ] = (\n",
    "                                                                    comp.isomeric_smiles\n",
    "                                                                )\n",
    "                                                        else:\n",
    "                                                            gnps_df[\n",
    "                                                                \"GNPSSMILES\"\n",
    "                                                            ][i] = \"\"\n",
    "                                            else:\n",
    "                                                gnps_df[\"GNPSSMILES\"][i] = \"\"\n",
    "                                        else:\n",
    "                                            gnps_df.drop(\n",
    "                                                [i], axis=0, inplace=True\n",
    "                                            )\n",
    "                                    gnps_df = gnps_df.drop_duplicates(\n",
    "                                        subset=[\"GNPSSMILES\"]\n",
    "                                    )\n",
    "                                    for k, row in gnps_df.iterrows():\n",
    "\n",
    "                                        if isNaN(gnps_df[\"GNPSSMILES\"][k]):\n",
    "\n",
    "                                            if (\n",
    "                                                \"[\"\n",
    "                                                in gnps_df[\"GNPScompound_name\"][\n",
    "                                                    k\n",
    "                                                ].split(\" \")[-1]\n",
    "                                            ):\n",
    "                                                string_chng = gnps_df[\n",
    "                                                    \"GNPScompound_name\"\n",
    "                                                ][k].split(\"[\")\n",
    "                                                # print(gnps_df['GNPScompound_name'][i])\n",
    "\n",
    "                                                # keep_names = []\n",
    "                                                for j in range(\n",
    "                                                    len(string_chng) - 1\n",
    "                                                ):\n",
    "                                                    gnps_df.loc[\n",
    "                                                        k, \"corr_names\"\n",
    "                                                    ] == string_chng[j]\n",
    "                                                    s = pcp.get_compounds(\n",
    "                                                        string_chng[j], \"name\"\n",
    "                                                    )\n",
    "\n",
    "                                                    if s:\n",
    "                                                        for comp in s:\n",
    "                                                            gnps_df[\n",
    "                                                                \"GNPSSMILES\"\n",
    "                                                            ][\n",
    "                                                                k\n",
    "                                                            ] = (\n",
    "                                                                comp.isomeric_smiles\n",
    "                                                            )\n",
    "                                                            gnps_df.loc[\n",
    "                                                                k, \"GNPSformula\"\n",
    "                                                            ] = (\n",
    "                                                                comp.molecular_formula\n",
    "                                                            )\n",
    "                                                            gnps_df.loc[\n",
    "                                                                k, \"GNPSinchi\"\n",
    "                                                            ] = Chem.MolToInchi(\n",
    "                                                                Chem.MolFromSmiles(\n",
    "                                                                    comp.isomeric_smiles\n",
    "                                                                )\n",
    "                                                            )\n",
    "\n",
    "                                                    else:\n",
    "                                                        gnps_df[\"GNPSSMILES\"][\n",
    "                                                            k\n",
    "                                                        ] = \"\"\n",
    "                                                        gnps_df.loc[\n",
    "                                                            k, \"GNPSformula\"\n",
    "                                                        ] = \"\"\n",
    "                                                        gnps_df.loc[\n",
    "                                                            k, \"GNPSinchi\"\n",
    "                                                        ] = \"\"\n",
    "                                        if not isNaN(gnps_df[\"GNPSSMILES\"][k]):\n",
    "                                            try:\n",
    "                                                sx = pcp.get_compounds(\n",
    "                                                    gnps_df[\"GNPSSMILES\"][k],\n",
    "                                                    \"smiles\",\n",
    "                                                )\n",
    "                                                gnps_df.loc[\n",
    "                                                    k, \"GNPSinchi\"\n",
    "                                                ] = Chem.MolToInchi(\n",
    "                                                    Chem.MolFromSmiles(\n",
    "                                                        comp.isomeric_smiles\n",
    "                                                    )\n",
    "                                                )\n",
    "                                                if sx:\n",
    "                                                    sx = str(sx)\n",
    "                                                    comp = pcp.Compound.from_cid(\n",
    "                                                        [\n",
    "                                                            int(x)\n",
    "                                                            for x in re.findall(\n",
    "                                                                r\"\\b\\d+\\b\", sx\n",
    "                                                            )\n",
    "                                                        ]\n",
    "                                                    )\n",
    "                                                    gnps_df.loc[\n",
    "                                                        k, \"GNPSformula\"\n",
    "                                                    ] = comp.molecular_formula\n",
    "\n",
    "                                            except Exception:\n",
    "                                                gnps_df.loc[\n",
    "                                                    k, \"GNPSformula\"\n",
    "                                                ] = \"\"\n",
    "                                                gnps_df.loc[k, \"GNPSinchi\"] = \"\"\n",
    "\n",
    "                                gnps_df = gnps_df.dropna(axis=0, how=\"all\")\n",
    "                                csvname = (\n",
    "                                    (os.path.splitext(fls_g)[0])\n",
    "                                    + \"proc\"\n",
    "                                    + \".csv\"\n",
    "                                )\n",
    "\n",
    "                                msp.loc[\n",
    "                                    mz, \"gnps_results_csv\"\n",
    "                                ] = csvname\n",
    "                                \n",
    "                                if not os.path.exists(csvname):\n",
    "                                    #print(\"this is wrong?\")\n",
    "                                    #print(csvname)\n",
    "                                    #print(os.path.splitext(fls_g)[0])\n",
    "                                    gnps_df.to_csv(csvname)\n",
    "\n",
    "\n",
    "            msp.to_csv(msp_file[0])\n",
    "            # HMDB Results\n",
    "            if Source == \"hmdb\" or Source == \"all\":\n",
    "                sub_dir = (\n",
    "                    entry + \"/spectral_dereplication/HMDB/\"\n",
    "                )\n",
    "                if os.path.exists(sub_dir):\n",
    "                    files = glob.glob(sub_dir + \"/*.csv\")\n",
    "                    files = [item for item in files if 'proc' not in item]\n",
    "                    if os.path.exists(sub_dir):\n",
    "                        # print(files)\n",
    "                        for mz, row in msp.iterrows():\n",
    "                            #print(mz)\n",
    "                            # print(msp[\"id_X\"][mz])\n",
    "                            for fls_h in files:\n",
    "                                 if msp[\"id_X\"][mz] in fls_h:\n",
    "                                        hmdb_df = pd.read_csv(fls_h)\n",
    "\n",
    "                                        if len(hmdb_df) > 0:\n",
    "                                            if \"HMDBSMILES\" in hmdb_df.columns:\n",
    "                                                #print(hmdb_df)\n",
    "                                                for i, row in hmdb_df.iterrows():\n",
    "                                                # if compound name is present\n",
    "                                                    if not HMDB_Scoring(hmdb_df, i):\n",
    "                                                        hmdb_df.drop(i, inplace=True)\n",
    "                                                hmdb_df = hmdb_df.drop_duplicates(\n",
    "                                                    subset=[\"HMDBSMILES\"]\n",
    "                                                )\n",
    "\n",
    "\n",
    "                                                csvname = (\n",
    "                                                    (os.path.splitext(fls_h)[0])\n",
    "                                                    + \"proc\"\n",
    "                                                    + \".csv\"\n",
    "                                                )  \n",
    "                                                msp.loc[\n",
    "                                                    mz, \"hmdb_results_csv\"\n",
    "                                                ] = csvname\n",
    "\n",
    "                                                if not os.path.exists(csvname):\n",
    "                                                    hmdb_df.to_csv(csvname) \n",
    "                                            else:    \n",
    "                                                # merge on basis of id, frame and hmdb result files\n",
    "                                                SmilesHM = pd.merge(\n",
    "                                                    hmdb_df,\n",
    "                                                    extract_smiles,\n",
    "                                                    left_on=hmdb_df.HMDBcompoundID,\n",
    "                                                    right_on=extract_smiles.DATABASE_ID,\n",
    "                                                )\n",
    "                                                hmdb_df[\"HMDBcompoundID\"] = np.nan\n",
    "                                                hmdb_df[\"HMDBSMILES\"] = np.nan\n",
    "                                                hmdb_df[\"HMDBformula\"] = np.nan\n",
    "                                                hmdb_df[\"HMDBcompound_name\"] = np.nan\n",
    "                                                for i, row in hmdb_df.iterrows():\n",
    "                                                    #print(i)\n",
    "                                                    # if compound name is present\n",
    "                                                    if HMDB_Scoring(hmdb_df, i):\n",
    "\n",
    "                                                        #hmdb_df.drop(i, inplace=True)\n",
    "                                                        for j, row in SmilesHM.iterrows():\n",
    "                                                            #print(\"SmilesHM\")\n",
    "                                                            # where index for both match, add the name and SMILES\n",
    "                                                            if (\n",
    "                                                                hmdb_df[\"HMDBcompoundID\"][i]\n",
    "                                                                == SmilesHM[\n",
    "                                                                    \"HMDBcompoundID\"\n",
    "                                                                ][j]\n",
    "                                                            ):\n",
    "                                                                hmdb_df.loc[\n",
    "                                                                    i, \"HMDBSMILES\"\n",
    "                                                                ] = SmilesHM[\"SMILES\"][\n",
    "                                                                    j\n",
    "                                                                ]  # add SMILES\n",
    "                                                                hmdb_df.loc[\n",
    "                                                                    i, \"HMDBcompound_name\"\n",
    "                                                                ] = SmilesHM[\n",
    "                                                                    \"GENERIC_NAME\"\n",
    "                                                                ][\n",
    "                                                                    j\n",
    "                                                                ]  # add name\n",
    "                                                                hmdb_df.loc[\n",
    "                                                                    i, \"HMDBformula\"\n",
    "                                                                ] = SmilesHM[\"FORMULA\"][\n",
    "                                                                    j\n",
    "\n",
    "                                                                ]\n",
    "                                                                #print(hmdb_df[\"HMDBSMILES\"][i])\n",
    "                #                             \n",
    "                                            #print(hmdb_df)\n",
    "#                                         hmdb_df = hmdb_df.drop_duplicates(\n",
    "#                                              subset=[\"HMDBSMILES\"]\n",
    "#                                          )\n",
    "                                        csvname = (\n",
    "                                            (os.path.splitext(fls_h)[0])\n",
    "                                            + \"proc\"\n",
    "                                            + \".csv\"\n",
    "                                        )  \n",
    "                                        msp.loc[\n",
    "                                            mz, \"hmdb_results_csv\"\n",
    "                                        ] = csvname\n",
    "\n",
    "                                        if not os.path.exists(csvname):\n",
    "                                            hmdb_df.to_csv(csvname) \n",
    "            msp.to_csv(msp_file[0])\n",
    "            # MASSBANK Results\n",
    "\n",
    "            # enter the directory with /spectral_dereplication/ results\n",
    "            if Source == \"mbank\" or Source == \"all\":\n",
    "\n",
    "                sub_dir = (\n",
    "                    \n",
    "                    entry\n",
    "                    + \"/spectral_dereplication/MassBank/\"\n",
    "                )\n",
    "                if os.path.exists(sub_dir):\n",
    "                    files = glob.glob(sub_dir + \"/*.csv\")\n",
    "                    files = [item for item in files if 'proc' not in item]\n",
    "                    for mz, row in msp.iterrows():\n",
    "                        # print(msp[\"id_X\"][mz])\n",
    "                        for fls_m in files:\n",
    "                            if msp[\"id_X\"][mz] in fls_m:\n",
    "                                mbank_df = pd.read_csv(fls_m)\n",
    "                                if len(mbank_df) > 0:\n",
    "\n",
    "                                    for i, row in mbank_df.iterrows():\n",
    "                                        # if compound name is present\n",
    "                                         if not MB_Scoring(mbank_df, i):\n",
    "                                            mbank_df.drop(i, inplace=True)\n",
    "                                mbank_df = mbank_df.drop_duplicates(\n",
    "                                    subset=[\"MBSMILES\"]\n",
    "                                )\n",
    "                                csvname = (\n",
    "                                    (os.path.splitext(fls_m)[0])\n",
    "                                    + \"proc\"\n",
    "                                    + \".csv\"\n",
    "                                )\n",
    "\n",
    "                                msp.loc[\n",
    "                                    mz, \"mbank_results_csv\"\n",
    "                                ] = csvname\n",
    "\n",
    "                                if not os.path.exists(csvname):\n",
    "\n",
    "                                    mbank_df.to_csv(csvname)\n",
    "            msp.to_csv(msp_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac754e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fb3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7b713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139d818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f983009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8848ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c6d1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnpsMNvsgnpsMAW(entry, mn_dir, name):\n",
    "    \n",
    "    \"\"\"gnpsMNvsgnpsMAW checks with tanimoto similarity score, whether\n",
    "    results from MAW GNPS and GNPS MN Masst results give same candidate\n",
    "\n",
    "    Parameters:\n",
    "    input_dir = input directory where you have stored the cytoscape file\n",
    "    from GNPS MN results and have exported edge and node tables from cytoscape\n",
    "    These two csv egde and node files must have \"edge\" and \"node\" in their name\n",
    "\n",
    "    Returns:\n",
    "    GNPS results with cluster index named\n",
    "    GNPS MN results with a confirmation column if MAW detected same candidate,\n",
    "    file named:\n",
    "\n",
    "    Usage:\n",
    "    gnpsMNvsgnpsMAW(mn_dir)\n",
    "    \"\"\"\n",
    "    # extract files with edges from MN results\n",
    "    GMNfile_edge = [f for f in os.listdir(mn_dir) if \"edge\" in f]\n",
    "    # extract files with nodes from MN results\n",
    "    GMNfile_node = [f for f in os.listdir(mn_dir) if \"node\" in f]\n",
    "    # read the files\n",
    "    GMNdf_node = pd.read_csv(mn_dir + \"/\" + GMNfile_node[0])\n",
    "    GMNdf_edge = pd.read_csv(mn_dir + \"/\" + GMNfile_edge[0])\n",
    "    # extract only important columns from both csv files\n",
    "    GMNdf_node = GMNdf_node[\n",
    "        [\n",
    "            \"precursor mass\",\n",
    "            \"RTMean\",\n",
    "            \"UniqueFileSources\",\n",
    "            \"charge\",\n",
    "            \"cluster index\",\n",
    "            \"componentindex\",\n",
    "            \"Compound_Name\",\n",
    "            \"Smiles\",\n",
    "            \"SpectrumID\",\n",
    "        ]\n",
    "    ]\n",
    "    GMNdf_edge = GMNdf_edge[\n",
    "        [\"cosine_score\", \"EdgeAnnotation\", \"node1\", \"node2\", \"mass_difference\"]\n",
    "    ]\n",
    "    # rename node1 to cluster index to merge nodes and edges results from MN\n",
    "    GMNdf_edge = GMNdf_edge.rename(columns={\"node1\": \"cluster index\"})\n",
    "    GMNdf = pd.merge(GMNdf_node, GMNdf_edge, on=\"cluster index\")\n",
    "    GMNdf.to_csv(mn_dir + \"/mergedN&E.csv\")\n",
    "    # Read results obtained from scoring_spec, named input_dir/MetabolomicsResults/scoredSpecDB.csv\n",
    "    SDB = pd.read_csv(entry + \"/mergedResults-with-one-Candidates.csv\")\n",
    "    # from GNPS MAW results and GNPS MN results, calculate how many MAW results are same as MN:\n",
    "    for i, row in SDB.iterrows():\n",
    "        for j, row in GMNdf.iterrows():\n",
    "             if not isNaN(SDB[\"SMILES\"][i]) and not isNaN(GMNdf[\"Smiles\"][j]):\n",
    "                if name in GMNdf[\"UniqueFileSources\"][j]: \n",
    "                    SKms = [\n",
    "                        Chem.MolFromSmiles(SDB[\"SMILES\"][i]),\n",
    "                        Chem.MolFromSmiles(GMNdf[\"Smiles\"][j]),\n",
    "                    ]\n",
    "                    SKfps = [\n",
    "                        AllChem.GetMorganFingerprintAsBitVect(x, 2, nBits=2048)\n",
    "                        for x in SKms\n",
    "                    ]\n",
    "                    SKtn = DataStructs.FingerprintSimilarity(SKfps[0], SKfps[1])\n",
    "                    if SKtn >= 0.99:\n",
    "                        print(SKtn)\n",
    "                        print(GMNdf[\"Smiles\"][j])\n",
    "                        SDB['AnnotationSources'][i] = SDB['AnnotationSources'][i] + \"|GNPSMN\"\n",
    "                        SDB['MSILevel'][i] = 2.0\n",
    "                        print(SDB['AnnotationSources'][i])\n",
    "                    #else:\n",
    "\n",
    "    SDB.to_csv(entry + \"/mergedResults-with-one-Candidates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8a7694a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DS_201124_SC_full_PRM_pos_03',\n",
       " 'DS_201124_SC_full_PRM_pos_04',\n",
       " 'DS200309_Scost_QC_70k_neg_PRM',\n",
       " 'DS_201124_SC_full_PRM_pos_05',\n",
       " 'DS_201124_SC_full_PRM_pos_02',\n",
       " 'DS_201124_SC_full_PRM_neg_03',\n",
       " 'DS_201124_SC_full_PRM_neg_04',\n",
       " 'DS200309_Scost_QC_70k_pos_PRM',\n",
       " 'DS_201124_SC_full_PRM_neg_05',\n",
       " 'DS_201124_SC_full_PRM_neg_02',\n",
       " 'DS_201124_SC_full_PRM_neg_10',\n",
       " 'DS_201124_SC_full_PRM_pos_10',\n",
       " 'DS_201124_SC_full_PRM_pos_07',\n",
       " 'DS_201124_SC_full_PRM_pos_09',\n",
       " 'DS_201124_SC_full_PRM_pos_08',\n",
       " 'DS_201124_SC_full_PRM_pos_01',\n",
       " 'DS_201124_SC_full_PRM_pos_06',\n",
       " 'DS_201124_SC_full_PRM_neg_07',\n",
       " 'DS_201124_SC_full_PRM_neg_09',\n",
       " 'DS_201124_SC_full_PRM_neg_08',\n",
       " 'DS_201124_SC_full_PRM_neg_01',\n",
       " 'DS_201124_SC_full_PRM_neg_06']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/mahnoorzulfiqar/OneDriveUNI/MAW-Diatom/SmarinoiRun1\"\n",
    "file = os.listdir(path)\n",
    "folders = [x for x in os.listdir(path) if x.startswith('DS')]\n",
    "folders2 = [x for x in folders if not '.mzML' in x]\n",
    "folders2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1aa8b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_dir = \"/Users/mahnoorzulfiqar/OneDriveUNI/MAW-Diatom/Molecular-Networking/GNPS/First-Run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dd69645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "OC(=O)C(N)Cc(c1)ccc(O)c1\n",
      "SIRIUS|MassBank|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCC(=O)O[C@H](CC([O-])=O)C[N+](C)(C)C\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "C(C[C@@H](C(=O)O)N)CN=C(N)N\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "C(C[C@@H](C(=O)O)N)CN=C(N)N\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "C(C[C@@H](C(=O)O)N)CN=C(N)N\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCC/C=C\\\\CCCCCCCC(=O)OCC(CO)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCC(=O)O[C@H](CC(O)=O)C[N+](C)(C)C\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCC(=O)O[C@H](CC(O)=O)C[N+](C)(C)C\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "O=C(O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "OC(=O)C(N)Cc(c1)ccc(O)c1\n",
      "MassBank|GNPS|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "OC(=O)C(N)Cc(c1)ccc(O)c1\n",
      "SIRIUS|MassBank|GNPS|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "C[N+](C)(C)CCOP(=O)(O)OC[C@H](O)CO\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "C[N+](C)(C)CCOP(=O)(O)OC[C@H](O)CO\n",
      "SIRIUS|MassBank|GNPS|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "C(C[C@@H](C(=O)O)N)CN=C(N)N\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "C(C[C@@H](C(=O)O)N)CN=C(N)N\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "C(C[C@@H](C(=O)O)N)CN=C(N)N\n",
      "SIRIUS|GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CSCC[C@@H](C(=O)O)N\n",
      "SIRIUS|MassBank|GNPS|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCCCCCCCC(=O)OC[C@H](COP(=O)([O-])OCC[N+](C)(C)C)O\n",
      "GNPS|GNPSMN|GNPSMN|GNPSMN|GNPSMN\n",
      "1.0\n",
      "OC(=O)C(N)Cc(c1)ccc(O)c1\n",
      "SIRIUS|MassBank|GNPS|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CSCC[C@@H](C(=O)O)N\n",
      "SIRIUS|MassBank|GNPS|GNPSMN|GNPSMN\n",
      "1.0\n",
      "CCCCCCCC\\\\C=C/CCCCCCCC(=O)OCC(COP(O)(=O)OCC(O)CO)OC(=O)CCCCCCC\\\\C=C/CCCCCCCC\n",
      "SIRIUS|GNPSMN|GNPSMN|GNPSMN\n"
     ]
    }
   ],
   "source": [
    "for i in folders2:\n",
    "    entry = path + \"/\" + i\n",
    "    name = i\n",
    "    gnpsMNvsgnpsMAW(entry, mn_dir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc7ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mawRpy)",
   "language": "python",
   "name": "mawrpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
